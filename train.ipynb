{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd # Data Processing \n",
    "from sklearn.model_selection import train_test_split # Categorize trainset, validation set \n",
    "\n",
    "import torch\n",
    "import torch.nn as nn \n",
    "from torch.utils.data import DataLoader, TensorDataset, ConcatDataset \n",
    "import torch.onnx   \n",
    "\n",
    "import glob # File to list\n",
    "from tqdm import tqdm # Process bar \n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MinMaxScalingLayer(nn.Module):\n",
    "    def __init__(self, min_features, max_features):\n",
    "        super(MinMaxScalingLayer, self).__init__()\n",
    "        self.register_buffer('min_features', torch.tensor(min_features, dtype=torch.float32))\n",
    "        self.register_buffer('max_features', torch.tensor(max_features, dtype=torch.float32))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return (x - self.min_features) / (self.max_features - self.min_features)  \n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "\n",
    "        self.hidden1 = nn.Linear(hidden_dim, hidden_dim) \n",
    "        self.leaky_relu1 = nn.LeakyReLU(negative_slope=0.01)\n",
    "\n",
    "        self.hidden2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.glu = nn.GLU() # Gated Linear Unit splits feature into half >> ex 128 to 64.\n",
    "\n",
    "        self.hidden3 = nn.Linear(hidden_dim//2, hidden_dim)\n",
    "        self.leaky_relu3 = nn.LeakyReLU(negative_slope=0.01)\n",
    "\n",
    "        self.hidden4 = nn.Linear(hidden_dim, hidden_dim) \n",
    "        self.glu2 = nn.GLU() # half\n",
    "\n",
    "        self.hidden5 = nn.Linear(hidden_dim//2, input_dim) \n",
    "        self.leaky_relu5 = nn.LeakyReLU(negative_slope=0.01)\n",
    "\n",
    "        # 32 x 64 / 128 x 64\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.leaky_relu1(self.hidden1(x))\n",
    "        out = self.glu(self.hidden2(out))\n",
    "        out = self.leaky_relu3(self.hidden3(out))\n",
    "        out = self.glu2(self.hidden4(out))\n",
    "        out = self.leaky_relu5(self.hidden5(out))\n",
    "        return out\n",
    "\n",
    "class MovePredictionModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, min_features, max_features): \n",
    "        super(MovePredictionModel, self).__init__()\n",
    "\n",
    "        self.minmax = MinMaxScalingLayer(min_features, max_features)\n",
    "\n",
    "        self.input_layer = nn.Linear(input_dim, hidden_dim)\n",
    "\n",
    "        # Residual block\n",
    "        self.residual_block = ResidualBlock(input_dim, hidden_dim)\n",
    "\n",
    "        self.hidden_skiplayer = nn.Linear(input_dim, hidden_dim)\n",
    "        self.leakyrelu_skiplayer = nn.LeakyReLU(negative_slope=0.01)\n",
    "\n",
    "        self.output_layer = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        normalized_out = self.minmax(x)\n",
    "        \n",
    "        processed_input = self.input_layer(normalized_out)\n",
    "        residual_out = self.residual_block(processed_input) # output tensor size: input_dim\n",
    "        \n",
    "        out = x + residual_out\n",
    "        out = self.hidden_skiplayer(out)\n",
    "        out = self.leakyrelu_skiplayer(out)\n",
    "        out = self.output_layer(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "INPUT_DIM = 9 # Linear vel + Linear acc + Angular vel + Angular acc + pos diff(vel*delta t) + rot diff(angvel * delta t) + bIsDrifting\n",
    "HIDDEN_DIM = 128\n",
    "OUTPUT_DIM = 3 # Pos diff x y  and rot diff z \n",
    "EPOCHS = 5000\n",
    "BATCH_SIZE = 64 \n",
    "LEARNING_RATE = 1e-4 #0.0005\n",
    "\n",
    "OUTPUT_FILENAME = 'model/test.pth'\n",
    "DATA_PATH = 'data'\n",
    "\n",
    "cuda_available = torch.cuda.is_available()\n",
    "print(cuda_available)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 6.7012e+01,  2.9694e+01,  0.0000e+00],\n",
      "        [ 7.6529e+01,  3.2894e+01, -5.2360e-02],\n",
      "        [ 8.6817e+01,  3.4000e+01, -5.2360e-02],\n",
      "        ...,\n",
      "        [-5.0843e+01, -2.8318e+01,  0.0000e+00],\n",
      "        [-2.8636e+01, -1.5950e+01,  0.0000e+00],\n",
      "        [-1.0118e+01, -5.6353e+00,  0.0000e+00]])\n",
      "torch.Size([64, 9])\n"
     ]
    }
   ],
   "source": [
    "# Read .csv files with pandas\n",
    "file_path = \"data/data0.csv\"\n",
    "data = pd.read_csv(file_path) # data frame \n",
    "\n",
    "# csv_file_paths = glob.glob(f'{DATA_PATH}/**/*.csv', recursive=True)\n",
    "# for path in csv_file_paths:\n",
    "#     print(path)\n",
    "\n",
    "# Convert to tensor \n",
    "x_features_csv = [i for i in range(9)] # 0 - 8 idx\n",
    "y_features_csv = [i for i in range(9, 12)] # 9 - 11 idx \n",
    "\n",
    "input_features = data.values[:,x_features_csv] # 0 - 8\n",
    "output_features = data.values[:, y_features_csv]\n",
    "\n",
    "X = torch.tensor(input_features, dtype=torch.float32)\n",
    "y = torch.tensor(output_features, dtype=torch.float32)\n",
    "\n",
    "print(y)\n",
    "#print(X.shape, y.shape)\n",
    "\n",
    "# Min max scaling\n",
    "x_min_features, x_max_features = input_features.min(axis=0), input_features.max(axis=0)\n",
    "y_min_features, y_max_features = output_features.min(axis=0), output_features.max(axis=0)\n",
    "\n",
    "\n",
    "\n",
    "# Dataset split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "val_dataset = TensorDataset(X_val, y_val)\n",
    " \n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "# print(f'Training samples: {len(train_loader.dataset)}')\n",
    "# print(f'Validation samples: {len(val_loader.dataset)}')\n",
    "\n",
    "batch = next(iter(train_loader))  # 첫 번째 배치 가져오기\n",
    "print(batch[0].shape) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Validation RMSE: 154.2901611328125\n",
      "New best model with RMSE: 154.2901611328125, saving model...\n",
      "Epoch 21, Validation RMSE: 117.06124114990234\n",
      "New best model with RMSE: 117.06124114990234, saving model...\n",
      "Epoch 41, Validation RMSE: 69.62760925292969\n",
      "New best model with RMSE: 69.62760925292969, saving model...\n",
      "Epoch 61, Validation RMSE: 35.888057708740234\n",
      "New best model with RMSE: 35.888057708740234, saving model...\n",
      "Epoch 81, Validation RMSE: 20.717180252075195\n",
      "New best model with RMSE: 20.717180252075195, saving model...\n",
      "Epoch 101, Validation RMSE: 15.308162689208984\n",
      "New best model with RMSE: 15.308162689208984, saving model...\n",
      "Epoch 121, Validation RMSE: 13.748313903808594\n",
      "New best model with RMSE: 13.748313903808594, saving model...\n",
      "Epoch 141, Validation RMSE: 11.310781478881836\n",
      "New best model with RMSE: 11.310781478881836, saving model...\n",
      "Epoch 161, Validation RMSE: 10.533082008361816\n",
      "New best model with RMSE: 10.533082008361816, saving model...\n",
      "Epoch 181, Validation RMSE: 10.045805931091309\n",
      "New best model with RMSE: 10.045805931091309, saving model...\n",
      "Epoch 201, Validation RMSE: 9.176700592041016\n",
      "New best model with RMSE: 9.176700592041016, saving model...\n",
      "Epoch 221, Validation RMSE: 8.819416046142578\n",
      "New best model with RMSE: 8.819416046142578, saving model...\n",
      "Epoch 241, Validation RMSE: 8.750406265258789\n",
      "New best model with RMSE: 8.750406265258789, saving model...\n",
      "Epoch 261, Validation RMSE: 9.041723251342773\n",
      "Validation RMSE did not improve. Patience counter: 1/20\n",
      "Epoch 281, Validation RMSE: 8.067850112915039\n",
      "New best model with RMSE: 8.067850112915039, saving model...\n",
      "Epoch 301, Validation RMSE: 8.354440689086914\n",
      "Validation RMSE did not improve. Patience counter: 1/20\n",
      "Epoch 321, Validation RMSE: 9.021383285522461\n",
      "Validation RMSE did not improve. Patience counter: 2/20\n",
      "Epoch 341, Validation RMSE: 7.677948474884033\n",
      "New best model with RMSE: 7.677948474884033, saving model...\n",
      "Epoch 361, Validation RMSE: 9.358108520507812\n",
      "Validation RMSE did not improve. Patience counter: 1/20\n",
      "Epoch 381, Validation RMSE: 7.615910530090332\n",
      "New best model with RMSE: 7.615910530090332, saving model...\n",
      "Epoch 401, Validation RMSE: 8.126595497131348\n",
      "Validation RMSE did not improve. Patience counter: 1/20\n",
      "Epoch 421, Validation RMSE: 7.414114952087402\n",
      "New best model with RMSE: 7.414114952087402, saving model...\n",
      "Epoch 441, Validation RMSE: 7.2008056640625\n",
      "New best model with RMSE: 7.2008056640625, saving model...\n",
      "Epoch 461, Validation RMSE: 7.199473857879639\n",
      "New best model with RMSE: 7.199473857879639, saving model...\n",
      "Epoch 481, Validation RMSE: 7.144472122192383\n",
      "New best model with RMSE: 7.144472122192383, saving model...\n",
      "Epoch 501, Validation RMSE: 6.964273452758789\n",
      "New best model with RMSE: 6.964273452758789, saving model...\n",
      "Epoch 521, Validation RMSE: 8.887020111083984\n",
      "Validation RMSE did not improve. Patience counter: 1/20\n",
      "Epoch 541, Validation RMSE: 7.379154205322266\n",
      "Validation RMSE did not improve. Patience counter: 2/20\n",
      "Epoch 561, Validation RMSE: 7.060140609741211\n",
      "Validation RMSE did not improve. Patience counter: 3/20\n",
      "Epoch 581, Validation RMSE: 6.958659648895264\n",
      "New best model with RMSE: 6.958659648895264, saving model...\n",
      "Epoch 601, Validation RMSE: 7.042877197265625\n",
      "Validation RMSE did not improve. Patience counter: 1/20\n",
      "Epoch 621, Validation RMSE: 6.748898506164551\n",
      "New best model with RMSE: 6.748898506164551, saving model...\n",
      "Epoch 641, Validation RMSE: 6.908550262451172\n",
      "Validation RMSE did not improve. Patience counter: 1/20\n",
      "Epoch 661, Validation RMSE: 6.686056613922119\n",
      "New best model with RMSE: 6.686056613922119, saving model...\n",
      "Epoch 681, Validation RMSE: 6.82290506362915\n",
      "Validation RMSE did not improve. Patience counter: 1/20\n",
      "Epoch 701, Validation RMSE: 7.347532749176025\n",
      "Validation RMSE did not improve. Patience counter: 2/20\n",
      "Epoch 721, Validation RMSE: 6.560263156890869\n",
      "New best model with RMSE: 6.560263156890869, saving model...\n",
      "Epoch 741, Validation RMSE: 6.7311320304870605\n",
      "Validation RMSE did not improve. Patience counter: 1/20\n",
      "Epoch 761, Validation RMSE: 6.637327194213867\n",
      "Validation RMSE did not improve. Patience counter: 2/20\n",
      "Epoch 781, Validation RMSE: 6.712614059448242\n",
      "Validation RMSE did not improve. Patience counter: 3/20\n",
      "Epoch 801, Validation RMSE: 6.561257839202881\n",
      "Validation RMSE did not improve. Patience counter: 4/20\n",
      "Epoch 821, Validation RMSE: 6.742496490478516\n",
      "Validation RMSE did not improve. Patience counter: 5/20\n",
      "Epoch 841, Validation RMSE: 6.870241641998291\n",
      "Validation RMSE did not improve. Patience counter: 6/20\n",
      "Epoch 861, Validation RMSE: 6.596418857574463\n",
      "Validation RMSE did not improve. Patience counter: 7/20\n",
      "Epoch 881, Validation RMSE: 7.055454730987549\n",
      "Validation RMSE did not improve. Patience counter: 8/20\n",
      "Epoch 901, Validation RMSE: 6.45896053314209\n",
      "New best model with RMSE: 6.45896053314209, saving model...\n",
      "Epoch 921, Validation RMSE: 6.4795756340026855\n",
      "Validation RMSE did not improve. Patience counter: 1/20\n",
      "Epoch 941, Validation RMSE: 6.395247936248779\n",
      "New best model with RMSE: 6.395247936248779, saving model...\n",
      "Epoch 961, Validation RMSE: 6.364011764526367\n",
      "New best model with RMSE: 6.364011764526367, saving model...\n",
      "Epoch 981, Validation RMSE: 6.4159722328186035\n",
      "Validation RMSE did not improve. Patience counter: 1/20\n",
      "Epoch 1001, Validation RMSE: 7.167376518249512\n",
      "Validation RMSE did not improve. Patience counter: 2/20\n",
      "Epoch 1021, Validation RMSE: 6.830404758453369\n",
      "Validation RMSE did not improve. Patience counter: 3/20\n",
      "Epoch 1041, Validation RMSE: 6.350306987762451\n",
      "New best model with RMSE: 6.350306987762451, saving model...\n",
      "Epoch 1061, Validation RMSE: 6.3157548904418945\n",
      "New best model with RMSE: 6.3157548904418945, saving model...\n",
      "Epoch 1081, Validation RMSE: 6.320395469665527\n",
      "Validation RMSE did not improve. Patience counter: 1/20\n",
      "Epoch 1101, Validation RMSE: 6.40817403793335\n",
      "Validation RMSE did not improve. Patience counter: 2/20\n",
      "Epoch 1121, Validation RMSE: 6.696441173553467\n",
      "Validation RMSE did not improve. Patience counter: 3/20\n",
      "Epoch 1141, Validation RMSE: 6.431466579437256\n",
      "Validation RMSE did not improve. Patience counter: 4/20\n",
      "Epoch 1161, Validation RMSE: 6.650312900543213\n",
      "Validation RMSE did not improve. Patience counter: 5/20\n",
      "Epoch 1181, Validation RMSE: 6.630108833312988\n",
      "Validation RMSE did not improve. Patience counter: 6/20\n",
      "Epoch 1201, Validation RMSE: 6.379268169403076\n",
      "Validation RMSE did not improve. Patience counter: 7/20\n",
      "Epoch 1221, Validation RMSE: 6.298170566558838\n",
      "New best model with RMSE: 6.298170566558838, saving model...\n",
      "Epoch 1241, Validation RMSE: 6.225121974945068\n",
      "New best model with RMSE: 6.225121974945068, saving model...\n",
      "Epoch 1261, Validation RMSE: 6.389726161956787\n",
      "Validation RMSE did not improve. Patience counter: 1/20\n",
      "Epoch 1281, Validation RMSE: 6.252800464630127\n",
      "Validation RMSE did not improve. Patience counter: 2/20\n",
      "Epoch 1301, Validation RMSE: 6.1730780601501465\n",
      "New best model with RMSE: 6.1730780601501465, saving model...\n",
      "Epoch 1321, Validation RMSE: 6.28659200668335\n",
      "Validation RMSE did not improve. Patience counter: 1/20\n",
      "Epoch 1341, Validation RMSE: 6.179415702819824\n",
      "Validation RMSE did not improve. Patience counter: 2/20\n",
      "Epoch 1361, Validation RMSE: 6.239351272583008\n",
      "Validation RMSE did not improve. Patience counter: 3/20\n",
      "Epoch 1381, Validation RMSE: 6.319373607635498\n",
      "Validation RMSE did not improve. Patience counter: 4/20\n",
      "Epoch 1401, Validation RMSE: 6.26226806640625\n",
      "Validation RMSE did not improve. Patience counter: 5/20\n",
      "Epoch 1421, Validation RMSE: 6.152383327484131\n",
      "New best model with RMSE: 6.152383327484131, saving model...\n",
      "Epoch 1441, Validation RMSE: 6.230223178863525\n",
      "Validation RMSE did not improve. Patience counter: 1/20\n",
      "Epoch 1461, Validation RMSE: 6.681113243103027\n",
      "Validation RMSE did not improve. Patience counter: 2/20\n",
      "Epoch 1481, Validation RMSE: 6.3962321281433105\n",
      "Validation RMSE did not improve. Patience counter: 3/20\n",
      "Epoch 1501, Validation RMSE: 6.746630668640137\n",
      "Validation RMSE did not improve. Patience counter: 4/20\n",
      "Epoch 1521, Validation RMSE: 6.336393356323242\n",
      "Validation RMSE did not improve. Patience counter: 5/20\n",
      "Epoch 1541, Validation RMSE: 6.248132705688477\n",
      "Validation RMSE did not improve. Patience counter: 6/20\n",
      "Epoch 1561, Validation RMSE: 6.278744697570801\n",
      "Validation RMSE did not improve. Patience counter: 7/20\n",
      "Epoch 1581, Validation RMSE: 6.213742733001709\n",
      "Validation RMSE did not improve. Patience counter: 8/20\n",
      "Epoch 1601, Validation RMSE: 6.2712178230285645\n",
      "Validation RMSE did not improve. Patience counter: 9/20\n",
      "Epoch 1621, Validation RMSE: 6.176446914672852\n",
      "Validation RMSE did not improve. Patience counter: 10/20\n",
      "Epoch 1641, Validation RMSE: 6.216763973236084\n",
      "Validation RMSE did not improve. Patience counter: 11/20\n",
      "Epoch 1661, Validation RMSE: 6.130196571350098\n",
      "New best model with RMSE: 6.130196571350098, saving model...\n",
      "Epoch 1681, Validation RMSE: 6.203393936157227\n",
      "Validation RMSE did not improve. Patience counter: 1/20\n",
      "Epoch 1701, Validation RMSE: 6.830173969268799\n",
      "Validation RMSE did not improve. Patience counter: 2/20\n",
      "Epoch 1721, Validation RMSE: 6.388035297393799\n",
      "Validation RMSE did not improve. Patience counter: 3/20\n",
      "Epoch 1741, Validation RMSE: 6.3378987312316895\n",
      "Validation RMSE did not improve. Patience counter: 4/20\n",
      "Epoch 1761, Validation RMSE: 6.259069442749023\n",
      "Validation RMSE did not improve. Patience counter: 5/20\n",
      "Epoch 1781, Validation RMSE: 6.142333984375\n",
      "Validation RMSE did not improve. Patience counter: 6/20\n",
      "Epoch 1801, Validation RMSE: 6.2260236740112305\n",
      "Validation RMSE did not improve. Patience counter: 7/20\n",
      "Epoch 1821, Validation RMSE: 6.297463417053223\n",
      "Validation RMSE did not improve. Patience counter: 8/20\n",
      "Epoch 1841, Validation RMSE: 6.2125325202941895\n",
      "Validation RMSE did not improve. Patience counter: 9/20\n",
      "Epoch 1861, Validation RMSE: 6.200895309448242\n",
      "Validation RMSE did not improve. Patience counter: 10/20\n",
      "Epoch 1881, Validation RMSE: 6.073138236999512\n",
      "New best model with RMSE: 6.073138236999512, saving model...\n",
      "Epoch 1901, Validation RMSE: 6.496082305908203\n",
      "Validation RMSE did not improve. Patience counter: 1/20\n",
      "Epoch 1921, Validation RMSE: 6.304019927978516\n",
      "Validation RMSE did not improve. Patience counter: 2/20\n",
      "Epoch 1941, Validation RMSE: 6.388784408569336\n",
      "Validation RMSE did not improve. Patience counter: 3/20\n",
      "Epoch 1961, Validation RMSE: 6.190045356750488\n",
      "Validation RMSE did not improve. Patience counter: 4/20\n",
      "Epoch 1981, Validation RMSE: 6.15156364440918\n",
      "Validation RMSE did not improve. Patience counter: 5/20\n",
      "Epoch 2001, Validation RMSE: 6.143747329711914\n",
      "Validation RMSE did not improve. Patience counter: 6/20\n",
      "Epoch 2021, Validation RMSE: 6.670588970184326\n",
      "Validation RMSE did not improve. Patience counter: 7/20\n",
      "Epoch 2041, Validation RMSE: 6.141486167907715\n",
      "Validation RMSE did not improve. Patience counter: 8/20\n",
      "Epoch 2061, Validation RMSE: 6.21602725982666\n",
      "Validation RMSE did not improve. Patience counter: 9/20\n",
      "Epoch 2081, Validation RMSE: 6.291298866271973\n",
      "Validation RMSE did not improve. Patience counter: 10/20\n",
      "Epoch 2101, Validation RMSE: 6.119485378265381\n",
      "Validation RMSE did not improve. Patience counter: 11/20\n",
      "Epoch 2121, Validation RMSE: 6.327082633972168\n",
      "Validation RMSE did not improve. Patience counter: 12/20\n",
      "Epoch 2141, Validation RMSE: 6.1286163330078125\n",
      "Validation RMSE did not improve. Patience counter: 13/20\n",
      "Epoch 2161, Validation RMSE: 6.489809036254883\n",
      "Validation RMSE did not improve. Patience counter: 14/20\n",
      "Epoch 2181, Validation RMSE: 6.194276332855225\n",
      "Validation RMSE did not improve. Patience counter: 15/20\n",
      "Epoch 2201, Validation RMSE: 6.20620059967041\n",
      "Validation RMSE did not improve. Patience counter: 16/20\n",
      "Epoch 2221, Validation RMSE: 6.224312782287598\n",
      "Validation RMSE did not improve. Patience counter: 17/20\n",
      "Epoch 2241, Validation RMSE: 6.158159255981445\n",
      "Validation RMSE did not improve. Patience counter: 18/20\n",
      "Epoch 2261, Validation RMSE: 6.430200099945068\n",
      "Validation RMSE did not improve. Patience counter: 19/20\n",
      "Epoch 2281, Validation RMSE: 6.963627815246582\n",
      "Validation RMSE did not improve. Patience counter: 20/20\n",
      "Early stopping triggered. End loop\n"
     ]
    }
   ],
   "source": [
    "# Set model\n",
    "model = MovePredictionModel(INPUT_DIM, HIDDEN_DIM, OUTPUT_DIM, x_min_features, x_max_features)\n",
    "\n",
    "if cuda_available:\n",
    "    model.cuda()\n",
    "\n",
    "epochs = EPOCHS\n",
    "best_val_rmse = float('inf')\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = LEARNING_RATE)\n",
    "\n",
    "#loss_contributions = torch.tensor([1,1,1e+2]) # Rule of thumb maybe\n",
    "y_std = y.std(dim=0)\n",
    "if cuda_available:\n",
    "    y_std = y_std.cuda()\n",
    "\n",
    "# Early stopping \n",
    "patience = 20\n",
    "es_counter = 0\n",
    "early_stop = False\n",
    "\n",
    "val_rmse_list = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # Tranining \n",
    "    model.train()\n",
    "    #for X_batch, y_batch in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs} Training\"):\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        if cuda_available:\n",
    "            X_batch, y_batch = X_batch.cuda(), y_batch.cuda()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        y_pred = model(X_batch)\n",
    "\n",
    "        loss = criterion(y_pred / y_std, y_batch / y_std)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    if epoch % 20 == 0 or epoch == epochs-1:\n",
    "\n",
    "        model.eval()\n",
    "\n",
    "        val_rmse = []\n",
    "        y_preds = []\n",
    "        y_actuals = []\n",
    "        with torch.no_grad():\n",
    "            #for X_batch, y_batch in tqdm(val_loader, desc=f\"Epoch {epoch+1}/{epochs} Validation\"):\n",
    "            for X_batch, y_batch in val_loader:\n",
    "\n",
    "                ## if you have GPU\n",
    "                if cuda_available:\n",
    "                    X_batch, y_batch = X_batch.cuda(), y_batch.cuda()\n",
    "\n",
    "                # inference the model\n",
    "                y_pred = model(X_batch)\n",
    "\n",
    "                # calculate RMSE\n",
    "                rmse = torch.sqrt(criterion(y_pred, y_batch)).cpu().numpy()\n",
    "                val_rmse.append(rmse)\n",
    "\n",
    "                # for the first batch\n",
    "                if len(y_preds) == 0:  \n",
    "                    y_preds = y_pred.cpu().numpy()\n",
    "                    y_actuals = y_batch.cpu().numpy()\n",
    "                # for the rest of the batches\n",
    "                else:  \n",
    "                    y_preds = np.vstack((y_preds, y_pred.cpu().numpy()))\n",
    "                    y_actuals = np.vstack((y_actuals, y_batch.cpu().numpy()))\n",
    "        epoch_val_rmse = np.mean(val_rmse)\n",
    "        val_rmse_list.append(epoch_val_rmse)\n",
    "\n",
    "        print(f\"Epoch {epoch+1}, Validation RMSE: {epoch_val_rmse}\")\n",
    "\n",
    "        if epoch_val_rmse < best_val_rmse:\n",
    "            best_val_rmse = epoch_val_rmse\n",
    "            print(f\"New best model with RMSE: {best_val_rmse}, saving model...\")\n",
    "            torch.save(model.state_dict(), OUTPUT_FILENAME)\n",
    "            es_counter = 0\n",
    "        else:\n",
    "            es_counter += 1\n",
    "            print(f\"Validation RMSE did not improve. Patience counter: {es_counter}/{patience}\")\n",
    "            if es_counter >= patience:\n",
    "                print(\"Early stopping triggered. End loop\")\n",
    "                early_stop = True\n",
    "                break\n",
    "    if early_stop:\n",
    "        model.load_state_dict(torch.load(output_features-OUTPUT_FILENAME))\n",
    "\n",
    "# Visualization\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(len(val_rmse_list)), val_rmse_list, label='Validation RMSE')\n",
    "plt.title('RMSE Over Epochs')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('RMSE')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\01076\\AppData\\Local\\Temp\\ipykernel_36912\\2053374196.py:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(OUTPUT_FILENAME))\n"
     ]
    }
   ],
   "source": [
    "ONNX_PATH = \"model/KartPredictionModel_ver2.onnx\"\n",
    "\n",
    "model = MovePredictionModel(INPUT_DIM, HIDDEN_DIM, OUTPUT_DIM, x_min_features, x_max_features)\n",
    "model.load_state_dict(torch.load(OUTPUT_FILENAME))  \n",
    "model.eval() \n",
    "\n",
    "dummy_input = torch.randn(1, INPUT_DIM) \n",
    "\n",
    "torch.onnx.export(\n",
    "    model, \n",
    "    dummy_input, \n",
    "    ONNX_PATH, \n",
    "    verbose=True, \n",
    "    input_names=['input'], \n",
    "    output_names=['output'] \n",
    "    #dynamic_axes={'input': {0: 'batch_size'}, 'output': {0: 'batch_size'}}\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lstm_test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
