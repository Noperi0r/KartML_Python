{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd # Data Processing \n",
    "from sklearn.model_selection import train_test_split # Categorize trainset, validation set \n",
    "\n",
    "import torch\n",
    "import torch.nn as nn \n",
    "from torch.utils.data import DataLoader, TensorDataset, ConcatDataset \n",
    "import torch.onnx\n",
    "\n",
    "import glob # File to list\n",
    "from tqdm import tqdm # Process bar \n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.hidden1 = nn.Linear(hidden_dim, hidden_dim) \n",
    "        self.leaky_relu1 = nn.LeakyReLU(negative_slope=0.01)\n",
    "\n",
    "        self.hidden2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.glu = nn.GLU() # Gated Linear Unit splits feature into half >> ex 128 to 64.\n",
    "\n",
    "        self.hidden3 = nn.Linear(hidden_dim//2, hidden_dim)\n",
    "        self.leaky_relu3 = nn.LeakyReLU(negative_slope=0.01)\n",
    "\n",
    "        self.hidden4 = nn.Linear(hidden_dim, hidden_dim) \n",
    "        self.glu2 = nn.GLU() # half\n",
    "\n",
    "        self.hidden5 = nn.Linear(hidden_dim//2, input_dim) \n",
    "        self.leaky_relu5 = nn.LeakyReLU(negative_slope=0.01)\n",
    "\n",
    "        # 32 x 64 / 128 x 64\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.leaky_relu1(self.hidden1(x))\n",
    "        out = self.glu(self.hidden2(out))\n",
    "        out = self.leaky_relu3(self.hidden3(out))\n",
    "        out = self.glu2(self.hidden4(out))\n",
    "        out = self.leaky_relu5(self.hidden5(out))\n",
    "        return out\n",
    "\n",
    "class MovePredictionModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(MovePredictionModel, self).__init__()\n",
    "        self.input_layer = nn.Linear(input_dim, hidden_dim)\n",
    "        #self.leaky_relu = nn.LeakyReLU(negative_slope=0.3)\n",
    "\n",
    "        # Residual block\n",
    "        self.residual_block = ResidualBlock(input_dim, hidden_dim)\n",
    "\n",
    "        # self.hidden_skiplayer = nn.Linear(hidden_dim//2, input_dim)\n",
    "        self.hidden_skiplayer = nn.Linear(input_dim, hidden_dim)\n",
    "        self.leakyrelu_skiplayer = nn.LeakyReLU(negative_slope=0.01)\n",
    "\n",
    "        #self.hidden = nn.Linear(hidden_dim, output_dim)\n",
    "        #self.leakyrelu = nn.LeakyReLU(negative_slope=0.02)\n",
    "        self.output_layer = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        #processed_input = self.leaky_relu(self.input_layer(x))\n",
    "        processed_input = self.input_layer(x)\n",
    "        residual_out = self.residual_block(processed_input) # output tensor size: input_dim\n",
    "        \n",
    "        out = x + residual_out\n",
    "        out = self.hidden_skiplayer(out)\n",
    "        out = self.leakyrelu_skiplayer(out)\n",
    "        out = self.output_layer(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "INPUT_DIM = 9 # Linear vel + Linear acc + Angular vel + Angular acc + pos diff(vel*delta t) + rot diff(angvel * delta t) + bIsDrifting\n",
    "HIDDEN_DIM = 128\n",
    "OUTPUT_DIM = 3 # Pos diff x y  and rot diff z \n",
    "EPOCHS = 5000\n",
    "BATCH_SIZE = 64 # TODO\n",
    "LEARNING_RATE = 1e-4 #0.0005\n",
    "\n",
    "OUTPUT_FILENAME = 'model/test.pth'\n",
    "DATA_PATH = 'data'\n",
    "\n",
    "cuda_available = torch.cuda.is_available()\n",
    "print(cuda_available)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 6.7012e+01,  2.9694e+01,  0.0000e+00],\n",
      "        [ 7.6529e+01,  3.2894e+01, -5.2360e-02],\n",
      "        [ 8.6817e+01,  3.4000e+01, -5.2360e-02],\n",
      "        ...,\n",
      "        [-5.0843e+01, -2.8318e+01,  0.0000e+00],\n",
      "        [-2.8636e+01, -1.5950e+01,  0.0000e+00],\n",
      "        [-1.0118e+01, -5.6353e+00,  0.0000e+00]])\n",
      "tensor([ 1.7037e-01,  1.3411e+00, -3.8174e-04])\n",
      "torch.Size([64, 9])\n"
     ]
    }
   ],
   "source": [
    "# Read .csv files with pandas\n",
    "file_path = \"data/data0.csv\"\n",
    "data = pd.read_csv(file_path) # data frame \n",
    "\n",
    "# csv_file_paths = glob.glob(f'{DATA_PATH}/**/*.csv', recursive=True)\n",
    "# for path in csv_file_paths:\n",
    "#     print(path)\n",
    "\n",
    "# Convert to tensor \n",
    "x_features_csv = [i for i in range(9)] # 0 - 8 idx\n",
    "y_features_csv = [i for i in range(9, 12)] # 9 - 11 idx \n",
    "\n",
    "input_features = data.values[:,x_features_csv] # 0 - 8\n",
    "output_features = data.values[:, y_features_csv]\n",
    "\n",
    "# Min max scaling\n",
    "x_min, x_max = input_features.min(axis=0), input_features.max(axis=0)\n",
    "y_min, y_max = output_features.min(axis=0), output_features.max(axis=0)\n",
    "\n",
    "input_features_scaled = (input_features - x_min) / (x_max - x_min)\n",
    "#output_features_scaled = (output_features - y_min) / (y_max - y_min)\n",
    "\n",
    "X = torch.tensor(input_features_scaled, dtype=torch.float32)\n",
    "y = torch.tensor(output_features, dtype=torch.float32)\n",
    "\n",
    "print(y)\n",
    "print(torch.mean(y, dim=0))\n",
    "#print(X.shape, y.shape)\n",
    "\n",
    "# Dataset split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "val_dataset = TensorDataset(X_val, y_val)\n",
    " \n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "# print(f'Training samples: {len(train_loader.dataset)}')\n",
    "# print(f'Validation samples: {len(val_loader.dataset)}')\n",
    "\n",
    "batch = next(iter(train_loader))  # 첫 번째 배치 가져오기\n",
    "print(batch[0].shape) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Validation RMSE: 155.19293212890625\n",
      "New best model with RMSE: 155.19293212890625, saving model...\n",
      "Epoch 21, Validation RMSE: 117.31716918945312\n",
      "New best model with RMSE: 117.31716918945312, saving model...\n",
      "Epoch 41, Validation RMSE: 104.00631713867188\n",
      "New best model with RMSE: 104.00631713867188, saving model...\n",
      "Epoch 61, Validation RMSE: 23.268033981323242\n",
      "New best model with RMSE: 23.268033981323242, saving model...\n",
      "Epoch 81, Validation RMSE: 17.510108947753906\n",
      "New best model with RMSE: 17.510108947753906, saving model...\n",
      "Epoch 101, Validation RMSE: 14.908616065979004\n",
      "New best model with RMSE: 14.908616065979004, saving model...\n",
      "Epoch 121, Validation RMSE: 11.775607109069824\n",
      "New best model with RMSE: 11.775607109069824, saving model...\n",
      "Epoch 141, Validation RMSE: 11.440333366394043\n",
      "New best model with RMSE: 11.440333366394043, saving model...\n",
      "Epoch 161, Validation RMSE: 12.931700706481934\n",
      "Validation RMSE did not improve. Patience counter: 1/20\n",
      "Epoch 181, Validation RMSE: 13.974493026733398\n",
      "Validation RMSE did not improve. Patience counter: 2/20\n",
      "Epoch 201, Validation RMSE: 14.530634880065918\n",
      "Validation RMSE did not improve. Patience counter: 3/20\n",
      "Epoch 221, Validation RMSE: 12.8792142868042\n",
      "Validation RMSE did not improve. Patience counter: 4/20\n",
      "Epoch 241, Validation RMSE: 11.99206256866455\n",
      "Validation RMSE did not improve. Patience counter: 5/20\n",
      "Epoch 261, Validation RMSE: 11.918856620788574\n",
      "Validation RMSE did not improve. Patience counter: 6/20\n",
      "Epoch 281, Validation RMSE: 14.506175994873047\n",
      "Validation RMSE did not improve. Patience counter: 7/20\n",
      "Epoch 301, Validation RMSE: 12.553913116455078\n",
      "Validation RMSE did not improve. Patience counter: 8/20\n",
      "Epoch 321, Validation RMSE: 11.825061798095703\n",
      "Validation RMSE did not improve. Patience counter: 9/20\n",
      "Epoch 341, Validation RMSE: 11.47573471069336\n",
      "Validation RMSE did not improve. Patience counter: 10/20\n",
      "Epoch 361, Validation RMSE: 11.028886795043945\n",
      "New best model with RMSE: 11.028886795043945, saving model...\n",
      "Epoch 381, Validation RMSE: 11.137951850891113\n",
      "Validation RMSE did not improve. Patience counter: 1/20\n",
      "Epoch 401, Validation RMSE: 10.967355728149414\n",
      "New best model with RMSE: 10.967355728149414, saving model...\n",
      "Epoch 421, Validation RMSE: 9.666489601135254\n",
      "New best model with RMSE: 9.666489601135254, saving model...\n",
      "Epoch 441, Validation RMSE: 9.552495956420898\n",
      "New best model with RMSE: 9.552495956420898, saving model...\n",
      "Epoch 461, Validation RMSE: 8.295708656311035\n",
      "New best model with RMSE: 8.295708656311035, saving model...\n",
      "Epoch 481, Validation RMSE: 8.113980293273926\n",
      "New best model with RMSE: 8.113980293273926, saving model...\n",
      "Epoch 501, Validation RMSE: 8.094075202941895\n",
      "New best model with RMSE: 8.094075202941895, saving model...\n",
      "Epoch 521, Validation RMSE: 8.876794815063477\n",
      "Validation RMSE did not improve. Patience counter: 1/20\n",
      "Epoch 541, Validation RMSE: 8.638480186462402\n",
      "Validation RMSE did not improve. Patience counter: 2/20\n",
      "Epoch 561, Validation RMSE: 8.48270034790039\n",
      "Validation RMSE did not improve. Patience counter: 3/20\n",
      "Epoch 581, Validation RMSE: 7.885262489318848\n",
      "New best model with RMSE: 7.885262489318848, saving model...\n",
      "Epoch 601, Validation RMSE: 8.228391647338867\n",
      "Validation RMSE did not improve. Patience counter: 1/20\n",
      "Epoch 621, Validation RMSE: 8.224712371826172\n",
      "Validation RMSE did not improve. Patience counter: 2/20\n",
      "Epoch 641, Validation RMSE: 8.336755752563477\n",
      "Validation RMSE did not improve. Patience counter: 3/20\n",
      "Epoch 661, Validation RMSE: 8.16288948059082\n",
      "Validation RMSE did not improve. Patience counter: 4/20\n",
      "Epoch 681, Validation RMSE: 7.832030773162842\n",
      "New best model with RMSE: 7.832030773162842, saving model...\n",
      "Epoch 701, Validation RMSE: 7.238018035888672\n",
      "New best model with RMSE: 7.238018035888672, saving model...\n",
      "Epoch 721, Validation RMSE: 7.215870380401611\n",
      "New best model with RMSE: 7.215870380401611, saving model...\n",
      "Epoch 741, Validation RMSE: 7.056828498840332\n",
      "New best model with RMSE: 7.056828498840332, saving model...\n",
      "Epoch 761, Validation RMSE: 7.095205783843994\n",
      "Validation RMSE did not improve. Patience counter: 1/20\n",
      "Epoch 781, Validation RMSE: 6.956152439117432\n",
      "New best model with RMSE: 6.956152439117432, saving model...\n",
      "Epoch 801, Validation RMSE: 6.950601577758789\n",
      "New best model with RMSE: 6.950601577758789, saving model...\n",
      "Epoch 821, Validation RMSE: 6.75416374206543\n",
      "New best model with RMSE: 6.75416374206543, saving model...\n",
      "Epoch 841, Validation RMSE: 6.690235137939453\n",
      "New best model with RMSE: 6.690235137939453, saving model...\n",
      "Epoch 861, Validation RMSE: 6.660780429840088\n",
      "New best model with RMSE: 6.660780429840088, saving model...\n",
      "Epoch 881, Validation RMSE: 6.584745407104492\n",
      "New best model with RMSE: 6.584745407104492, saving model...\n",
      "Epoch 901, Validation RMSE: 6.669375419616699\n",
      "Validation RMSE did not improve. Patience counter: 1/20\n",
      "Epoch 921, Validation RMSE: 6.563638210296631\n",
      "New best model with RMSE: 6.563638210296631, saving model...\n",
      "Epoch 941, Validation RMSE: 6.552618503570557\n",
      "New best model with RMSE: 6.552618503570557, saving model...\n",
      "Epoch 961, Validation RMSE: 6.406954765319824\n",
      "New best model with RMSE: 6.406954765319824, saving model...\n",
      "Epoch 981, Validation RMSE: 6.388178825378418\n",
      "New best model with RMSE: 6.388178825378418, saving model...\n",
      "Epoch 1001, Validation RMSE: 6.332096576690674\n",
      "New best model with RMSE: 6.332096576690674, saving model...\n",
      "Epoch 1021, Validation RMSE: 6.24934196472168\n",
      "New best model with RMSE: 6.24934196472168, saving model...\n",
      "Epoch 1041, Validation RMSE: 6.299041271209717\n",
      "Validation RMSE did not improve. Patience counter: 1/20\n",
      "Epoch 1061, Validation RMSE: 6.239839553833008\n",
      "New best model with RMSE: 6.239839553833008, saving model...\n",
      "Epoch 1081, Validation RMSE: 6.221886157989502\n",
      "New best model with RMSE: 6.221886157989502, saving model...\n",
      "Epoch 1101, Validation RMSE: 6.171707630157471\n",
      "New best model with RMSE: 6.171707630157471, saving model...\n",
      "Epoch 1121, Validation RMSE: 6.190324306488037\n",
      "Validation RMSE did not improve. Patience counter: 1/20\n",
      "Epoch 1141, Validation RMSE: 6.206469535827637\n",
      "Validation RMSE did not improve. Patience counter: 2/20\n",
      "Epoch 1161, Validation RMSE: 6.248266696929932\n",
      "Validation RMSE did not improve. Patience counter: 3/20\n",
      "Epoch 1181, Validation RMSE: 6.437254428863525\n",
      "Validation RMSE did not improve. Patience counter: 4/20\n",
      "Epoch 1201, Validation RMSE: 6.315349102020264\n",
      "Validation RMSE did not improve. Patience counter: 5/20\n",
      "Epoch 1221, Validation RMSE: 6.6660027503967285\n",
      "Validation RMSE did not improve. Patience counter: 6/20\n",
      "Epoch 1241, Validation RMSE: 7.3736162185668945\n",
      "Validation RMSE did not improve. Patience counter: 7/20\n",
      "Epoch 1261, Validation RMSE: 7.327373504638672\n",
      "Validation RMSE did not improve. Patience counter: 8/20\n",
      "Epoch 1281, Validation RMSE: 7.358059883117676\n",
      "Validation RMSE did not improve. Patience counter: 9/20\n",
      "Epoch 1301, Validation RMSE: 7.854706287384033\n",
      "Validation RMSE did not improve. Patience counter: 10/20\n",
      "Epoch 1321, Validation RMSE: 8.249403953552246\n",
      "Validation RMSE did not improve. Patience counter: 11/20\n",
      "Epoch 1341, Validation RMSE: 8.748702049255371\n",
      "Validation RMSE did not improve. Patience counter: 12/20\n",
      "Epoch 1361, Validation RMSE: 8.914450645446777\n",
      "Validation RMSE did not improve. Patience counter: 13/20\n",
      "Epoch 1381, Validation RMSE: 8.383745193481445\n",
      "Validation RMSE did not improve. Patience counter: 14/20\n",
      "Epoch 1401, Validation RMSE: 8.241307258605957\n",
      "Validation RMSE did not improve. Patience counter: 15/20\n",
      "Epoch 1421, Validation RMSE: 8.102092742919922\n",
      "Validation RMSE did not improve. Patience counter: 16/20\n",
      "Epoch 1441, Validation RMSE: 8.309635162353516\n",
      "Validation RMSE did not improve. Patience counter: 17/20\n",
      "Epoch 1461, Validation RMSE: 8.641587257385254\n",
      "Validation RMSE did not improve. Patience counter: 18/20\n",
      "Epoch 1481, Validation RMSE: 8.980186462402344\n",
      "Validation RMSE did not improve. Patience counter: 19/20\n",
      "Epoch 1501, Validation RMSE: 8.631182670593262\n",
      "Validation RMSE did not improve. Patience counter: 20/20\n",
      "Early stopping triggered. End loop\n"
     ]
    }
   ],
   "source": [
    "# Set model\n",
    "model = MovePredictionModel(INPUT_DIM, HIDDEN_DIM, OUTPUT_DIM)\n",
    "#model = ResidualBlock(INPUT_DIM, HIDDEN_DIM)\n",
    "if cuda_available:\n",
    "    model.cuda()\n",
    "\n",
    "epochs = EPOCHS\n",
    "best_val_rmse = float('inf')\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = LEARNING_RATE)\n",
    "\n",
    "loss_weights = torch.tensor([1,1,1e+2]) # Output features average >> [ 1.7037e-01,  1.3411e+00, -3.8174e-04] therefore I multiplied 1e+2 to the 3rd feature\n",
    "if cuda_available:\n",
    "    loss_weights = loss_weights.cuda()\n",
    "\n",
    "# Early stopping \n",
    "patience = 20\n",
    "es_counter = 0\n",
    "early_stop = False\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # Tranining \n",
    "    model.train()\n",
    "    #for X_batch, y_batch in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs} Training\"):\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        if cuda_available:\n",
    "            X_batch, y_batch = X_batch.cuda(), y_batch.cuda()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        y_pred = model(X_batch)\n",
    "\n",
    "        loss = criterion(y_pred * loss_weights, y_batch * loss_weights)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    if epoch % 20 == 0 or epoch == epochs-1:\n",
    "\n",
    "        model.eval()\n",
    "\n",
    "        val_rmse = []\n",
    "        y_preds = []\n",
    "        y_actuals = []\n",
    "        with torch.no_grad():\n",
    "            #for X_batch, y_batch in tqdm(val_loader, desc=f\"Epoch {epoch+1}/{epochs} Validation\"):\n",
    "            for X_batch, y_batch in val_loader:\n",
    "\n",
    "                ## if you have GPU\n",
    "                if cuda_available:\n",
    "                    X_batch, y_batch = X_batch.cuda(), y_batch.cuda()\n",
    "\n",
    "                # inference the model\n",
    "                y_pred = model(X_batch)\n",
    "\n",
    "                # calculate RMSE\n",
    "                rmse = torch.sqrt(criterion(y_pred, y_batch)).cpu().numpy()\n",
    "                val_rmse.append(rmse)\n",
    "\n",
    "                # for the first batch\n",
    "                if len(y_preds) == 0:  \n",
    "                    y_preds = y_pred.cpu().numpy()\n",
    "                    y_actuals = y_batch.cpu().numpy()\n",
    "                # for the rest of the batches\n",
    "                else:  \n",
    "                    y_preds = np.vstack((y_preds, y_pred.cpu().numpy()))\n",
    "                    y_actuals = np.vstack((y_actuals, y_batch.cpu().numpy()))\n",
    "        epoch_val_rmse = np.mean(val_rmse)\n",
    "        print(f\"Epoch {epoch+1}, Validation RMSE: {epoch_val_rmse}\")\n",
    "\n",
    "        if epoch_val_rmse < best_val_rmse:\n",
    "            best_val_rmse = epoch_val_rmse\n",
    "            print(f\"New best model with RMSE: {best_val_rmse}, saving model...\")\n",
    "            torch.save(model.state_dict(), OUTPUT_FILENAME)\n",
    "            es_counter = 0\n",
    "        else:\n",
    "            es_counter += 1\n",
    "            print(f\"Validation RMSE did not improve. Patience counter: {es_counter}/{patience}\")\n",
    "            if es_counter >= patience:\n",
    "                print(\"Early stopping triggered. End loop\")\n",
    "                early_stop = True\n",
    "                break\n",
    "    if early_stop:\n",
    "        model.load_state_dict(torch.load(output_features-OUTPUT_FILENAME))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\01076\\AppData\\Local\\Temp\\ipykernel_62660\\2314137942.py:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(OUTPUT_FILENAME))  # pth 파일 로드\n"
     ]
    }
   ],
   "source": [
    "ONNX_PATH = \"model/KartPredictionModel.onnx\"\n",
    "\n",
    "model = MovePredictionModel(INPUT_DIM, HIDDEN_DIM, OUTPUT_DIM)\n",
    "model.load_state_dict(torch.load(OUTPUT_FILENAME))  \n",
    "model.eval() \n",
    "\n",
    "dummy_input = torch.randn(1, INPUT_DIM) \n",
    "\n",
    "torch.onnx.export(\n",
    "    model, \n",
    "    dummy_input, \n",
    "    ONNX_PATH, \n",
    "    verbose=True, \n",
    "    input_names=['input'], \n",
    "    output_names=['output'], \n",
    "    dynamic_axes={'input': {0: 'batch_size'}, 'output': {0: 'batch_size'}}\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lstm_test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
