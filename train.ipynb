{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-22T00:26:43.591508Z",
     "start_time": "2024-12-22T00:26:43.586505Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd # Data Processing \n",
    "from sklearn.model_selection import train_test_split # Categorize trainset, validation set \n",
    "\n",
    "import torch\n",
    "import torch.nn as nn \n",
    "from torch.utils.data import DataLoader, TensorDataset, ConcatDataset \n",
    "import torch.onnx   \n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "import glob # File to list\n",
    "from tqdm import tqdm # Process bar \n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-22T00:26:43.607045Z",
     "start_time": "2024-12-22T00:26:43.592509Z"
    }
   },
   "outputs": [],
   "source": [
    "class MinMaxScalingLayer(nn.Module):\n",
    "    def __init__(self, min_features, max_features):\n",
    "        super(MinMaxScalingLayer, self).__init__()\n",
    "        self.register_buffer('min_features', torch.tensor(min_features, dtype=torch.float32))\n",
    "        self.register_buffer('max_features', torch.tensor(max_features, dtype=torch.float32))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return (x - self.min_features) / (self.max_features - self.min_features)  \n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "\n",
    "        self.hidden1 = nn.Linear(hidden_dim, hidden_dim) \n",
    "        self.leaky_relu1 = nn.LeakyReLU(negative_slope=0.01)\n",
    "\n",
    "        self.hidden2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.glu = nn.GLU() # Gated Linear Unit splits feature into half >> ex 128 to 64.\n",
    "\n",
    "        self.hidden3 = nn.Linear(hidden_dim//2, hidden_dim)\n",
    "        self.leaky_relu3 = nn.LeakyReLU(negative_slope=0.01)\n",
    "\n",
    "        self.hidden4 = nn.Linear(hidden_dim, hidden_dim) \n",
    "        self.glu2 = nn.GLU() # half\n",
    "\n",
    "        self.hidden5 = nn.Linear(hidden_dim//2, input_dim) \n",
    "        self.leaky_relu5 = nn.LeakyReLU(negative_slope=0.01)\n",
    "\n",
    "        # 32 x 64 / 128 x 64\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.leaky_relu1(self.hidden1(x))\n",
    "        out = self.glu(self.hidden2(out))\n",
    "        out = self.leaky_relu3(self.hidden3(out))\n",
    "        out = self.glu2(self.hidden4(out))\n",
    "        out = self.leaky_relu5(self.hidden5(out))\n",
    "        return out\n",
    "\n",
    "class MovePredictionModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, min_features, max_features): \n",
    "        super(MovePredictionModel, self).__init__()\n",
    "\n",
    "        self.minmax = MinMaxScalingLayer(min_features, max_features)\n",
    "\n",
    "        self.input_layer = nn.Linear(input_dim, hidden_dim)\n",
    "\n",
    "        # Residual block\n",
    "        self.residual_block = ResidualBlock(input_dim, hidden_dim)\n",
    "\n",
    "        self.hidden_skiplayer = nn.Linear(input_dim, hidden_dim)\n",
    "        self.leakyrelu_skiplayer = nn.LeakyReLU(negative_slope=0.01)\n",
    "\n",
    "        self.output_layer = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        normalized_out = self.minmax(x)\n",
    "        \n",
    "        processed_input = self.input_layer(normalized_out)\n",
    "        residual_out = self.residual_block(processed_input) # output tensor size: input_dim\n",
    "        \n",
    "        out = normalized_out + residual_out # \n",
    "        out = self.hidden_skiplayer(out)\n",
    "        out = self.leakyrelu_skiplayer(out)\n",
    "        out = self.output_layer(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-22T00:26:43.622352Z",
     "start_time": "2024-12-22T00:26:43.608053Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "INPUT_DIM = 9 # Linear vel + Linear acc + Angular vel + Angular acc + pos diff(vel*delta t) + rot diff(angvel * delta t) + bIsDrifting\n",
    "HIDDEN_DIM = 128\n",
    "OUTPUT_DIM = 3 # Pos diff x y  and rot diff z \n",
    "EPOCHS = 5000\n",
    "BATCH_SIZE = 64 \n",
    "LEARNING_RATE = 1e-3 # 스케쥴러 있으니 LR 좀 크게 설정\n",
    "\n",
    "OUTPUT_FILENAME = 'model/test.pth'\n",
    "DATA_PATH = 'data'\n",
    "\n",
    "cuda_available = torch.cuda.is_available()\n",
    "print(cuda_available)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-22T00:26:43.654903Z",
     "start_time": "2024-12-22T00:26:43.623353Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12767\n",
      "tensor([[ 6.7012e+01,  2.9694e+01,  0.0000e+00],\n",
      "        [ 7.6529e+01,  3.2894e+01, -5.2360e-02],\n",
      "        [ 8.6817e+01,  3.4000e+01, -5.2360e-02],\n",
      "        ...,\n",
      "        [ 1.3340e+02, -1.8288e+02,  0.0000e+00],\n",
      "        [ 1.1309e+02, -1.5504e+02,  0.0000e+00],\n",
      "        [ 8.0898e+01, -1.1090e+02,  0.0000e+00]])\n",
      "torch.Size([64, 9])\n"
     ]
    }
   ],
   "source": [
    "# Read .csv files with pandas\n",
    "folder_path = \"data/\"\n",
    "csv_file_paths = glob.glob(f\"{folder_path}/*.csv\")\n",
    "\n",
    "data_frames = [pd.read_csv(path) for path in csv_file_paths]\n",
    "data = pd.concat(data_frames, ignore_index=True)\n",
    "print(len(data))\n",
    "# csv_file_paths = glob.glob(f'{DATA_PATH}/**/*.csv', recursive=True)\n",
    "# for path in csv_file_paths:\n",
    "#     print(path)\n",
    "\n",
    "# Convert to tensor \n",
    "x_features_csv = [i for i in range(9)] # 0 - 8 idx\n",
    "y_features_csv = [i for i in range(9, 12)] # 9 - 11 idx \n",
    "\n",
    "input_features = data.values[:,x_features_csv] # 0 - 8\n",
    "output_features = data.values[:, y_features_csv]\n",
    "\n",
    "X = torch.tensor(input_features, dtype=torch.float32)\n",
    "y = torch.tensor(output_features, dtype=torch.float32)\n",
    "\n",
    "print(y)\n",
    "#print(X.shape, y.shape)\n",
    "\n",
    "# Min max scaling\n",
    "x_min_features, x_max_features = input_features.min(axis=0), input_features.max(axis=0)\n",
    "y_min_features, y_max_features = output_features.min(axis=0), output_features.max(axis=0)\n",
    "\n",
    "# Dataset split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "val_dataset = TensorDataset(X_val, y_val)\n",
    " \n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "# print(f'Training samples: {len(train_loader.dataset)}')\n",
    "# print(f'Validation samples: {len(val_loader.dataset)}')\n",
    "\n",
    "batch = next(iter(train_loader))  # 첫 번째 배치 가져오기\n",
    "print(batch[0].shape) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-22T00:48:55.038395Z",
     "start_time": "2024-12-22T00:26:43.655906Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Validation RMSE: 155.03733825683594\n",
      "New best model with RMSE: 155.03733825683594, saving model...\n",
      "Epoch 21, Validation RMSE: 18.598468780517578\n",
      "New best model with RMSE: 18.598468780517578, saving model...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 48\u001b[0m\n\u001b[0;32m     45\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m model(X_batch)\n\u001b[0;32m     47\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(y_pred \u001b[38;5;241m/\u001b[39m y_std, y_batch \u001b[38;5;241m/\u001b[39m y_std)\n\u001b[1;32m---> 48\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m     49\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m epoch \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m20\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m epoch \u001b[38;5;241m==\u001b[39m epochs\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\01076\\anaconda3\\envs\\lstm_test\\Lib\\site-packages\\torch\\_tensor.py:581\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    571\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    572\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    573\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    574\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    579\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    580\u001b[0m     )\n\u001b[1;32m--> 581\u001b[0m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mbackward(\n\u001b[0;32m    582\u001b[0m     \u001b[38;5;28mself\u001b[39m, gradient, retain_graph, create_graph, inputs\u001b[38;5;241m=\u001b[39minputs\n\u001b[0;32m    583\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\01076\\anaconda3\\envs\\lstm_test\\Lib\\site-packages\\torch\\autograd\\__init__.py:347\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    342\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    344\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    345\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    346\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 347\u001b[0m _engine_run_backward(\n\u001b[0;32m    348\u001b[0m     tensors,\n\u001b[0;32m    349\u001b[0m     grad_tensors_,\n\u001b[0;32m    350\u001b[0m     retain_graph,\n\u001b[0;32m    351\u001b[0m     create_graph,\n\u001b[0;32m    352\u001b[0m     inputs,\n\u001b[0;32m    353\u001b[0m     allow_unreachable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    354\u001b[0m     accumulate_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    355\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\01076\\anaconda3\\envs\\lstm_test\\Lib\\site-packages\\torch\\autograd\\graph.py:825\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[1;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    823\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[0;32m    824\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 825\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Variable\u001b[38;5;241m.\u001b[39m_execution_engine\u001b[38;5;241m.\u001b[39mrun_backward(  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    826\u001b[0m         t_outputs, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    827\u001b[0m     )  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    828\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    829\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Set model\n",
    "model = MovePredictionModel(INPUT_DIM, HIDDEN_DIM, OUTPUT_DIM, x_min_features, x_max_features)\n",
    "\n",
    "if cuda_available:\n",
    "    model.cuda()\n",
    "\n",
    "epochs = EPOCHS\n",
    "best_val_rmse = float('inf')\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = LEARNING_RATE)\n",
    "\n",
    "# 스케줄러 추가\n",
    "scheduler = ReduceLROnPlateau(\n",
    "    optimizer, \n",
    "    mode='min',      # epoch_val_rmse가 낮을수록 좋은 지표\n",
    "    factor=0.5,      # LR을 1/2로 감소\n",
    "    patience=10,     # 10 epoch 동안 개선 없으면 LR 감소\n",
    "    threshold=1e-4,  # 개선 판단 임계값 (지표가 이 정도로 줄어들어야 개선으로 간주)\n",
    "    cooldown=0, \n",
    "    min_lr=1e-7,     # LR이 너무 작아지는 것 방지\n",
    ")\n",
    "\n",
    "#loss_contributions = torch.tensor([1,1,1e+2]) # Rule of thumb maybe\n",
    "y_std = y.std(dim=0)\n",
    "if cuda_available:\n",
    "    y_std = y_std.cuda()\n",
    "\n",
    "# Early stopping \n",
    "patience = 20\n",
    "es_counter = 0\n",
    "early_stop = False\n",
    "\n",
    "val_rmse_list = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # Tranining \n",
    "    model.train()\n",
    "    #for X_batch, y_batch in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs} Training\"):\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        if cuda_available:\n",
    "            X_batch, y_batch = X_batch.cuda(), y_batch.cuda()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        y_pred = model(X_batch)\n",
    "\n",
    "        loss = criterion(y_pred / y_std, y_batch / y_std)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    if epoch % 20 == 0 or epoch == epochs-1:\n",
    "\n",
    "        model.eval()\n",
    "\n",
    "        val_rmse = []\n",
    "        y_preds = []\n",
    "        y_actuals = []\n",
    "        with torch.no_grad():\n",
    "            #for X_batch, y_batch in tqdm(val_loader, desc=f\"Epoch {epoch+1}/{epochs} Validation\"):\n",
    "            for X_batch, y_batch in val_loader:\n",
    "\n",
    "                ## if you have GPU\n",
    "                if cuda_available:\n",
    "                    X_batch, y_batch = X_batch.cuda(), y_batch.cuda()\n",
    "\n",
    "                # inference the model\n",
    "                y_pred = model(X_batch)\n",
    "\n",
    "                # calculate RMSE\n",
    "                rmse = torch.sqrt(criterion(y_pred, y_batch)).cpu().numpy()\n",
    "                val_rmse.append(rmse)\n",
    "\n",
    "                # for the first batch\n",
    "                if len(y_preds) == 0:  \n",
    "                    y_preds = y_pred.cpu().numpy()\n",
    "                    y_actuals = y_batch.cpu().numpy()\n",
    "                # for the rest of the batches\n",
    "                else:  \n",
    "                    y_preds = np.vstack((y_preds, y_pred.cpu().numpy()))\n",
    "                    y_actuals = np.vstack((y_actuals, y_batch.cpu().numpy()))\n",
    "        epoch_val_rmse = np.mean(val_rmse)\n",
    "        val_rmse_list.append(epoch_val_rmse)\n",
    "\n",
    "        print(f\"Epoch {epoch+1}, Validation RMSE: {epoch_val_rmse}\")\n",
    "        \n",
    "        # (중요) ReduceLROnPlateau는 step() 인자로 \"검증 지표(loss)\"를 넣어야 함\n",
    "        # 여기서는 epoch_val_rmse 낮을수록 좋으므로 mode='min' 설정\n",
    "        scheduler.step(epoch_val_rmse) \n",
    "\n",
    "        if epoch_val_rmse < best_val_rmse:\n",
    "            best_val_rmse = epoch_val_rmse\n",
    "            print(f\"New best model with RMSE: {best_val_rmse}, saving model...\")\n",
    "            torch.save(model.state_dict(), OUTPUT_FILENAME)\n",
    "            es_counter = 0\n",
    "        else:\n",
    "            es_counter += 1\n",
    "            print(f\"Validation RMSE did not improve. Patience counter: {es_counter}/{patience}\")\n",
    "            if es_counter >= patience:\n",
    "                print(\"Early stopping triggered. End loop\")\n",
    "                early_stop = True\n",
    "                break\n",
    "    if early_stop:\n",
    "        model.load_state_dict(torch.load(OUTPUT_FILENAME))\n",
    "        break\n",
    "\n",
    "# Visualization\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(len(val_rmse_list)), val_rmse_list, label='Validation RMSE')\n",
    "plt.title('RMSE Over Epochs')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('RMSE')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-22T00:52:47.013542Z",
     "start_time": "2024-12-22T00:52:46.947365Z"
    }
   },
   "outputs": [],
   "source": [
    "ONNX_PATH = \"model/KartPredictionModel_ver3.onnx\"\n",
    "\n",
    "model = MovePredictionModel(INPUT_DIM, HIDDEN_DIM, OUTPUT_DIM, x_min_features, x_max_features)\n",
    "model.load_state_dict(torch.load(OUTPUT_FILENAME))  \n",
    "model.eval() \n",
    "\n",
    "dummy_input = torch.randn(1, INPUT_DIM) \n",
    "\n",
    "torch.onnx.export(\n",
    "    model, \n",
    "    dummy_input, \n",
    "    ONNX_PATH, \n",
    "    verbose=True, \n",
    "    input_names=['input'], \n",
    "    output_names=['output'] \n",
    "    #dynamic_axes={'input': {0: 'batch_size'}, 'output': {0: 'batch_size'}}\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-22T00:48:55.085542Z",
     "start_time": "2024-12-22T00:48:55.071015Z"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lstm_test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
