{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd # Data Processing \n",
    "from sklearn.model_selection import train_test_split # Categorize trainset, validation set \n",
    "\n",
    "import torch\n",
    "import torch.nn as nn \n",
    "from torch.utils.data import DataLoader, TensorDataset, ConcatDataset \n",
    "import torch.onnx\n",
    "\n",
    "import glob # File to list\n",
    "from tqdm import tqdm # Process bar \n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.hidden1 = nn.Linear(hidden_dim, hidden_dim) \n",
    "        self.leaky_relu1 = nn.LeakyReLU(negative_slope=0.01)\n",
    "\n",
    "        self.hidden2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.glu = nn.GLU() # Gated Linear Unit splits feature into half >> ex 128 to 64.\n",
    "\n",
    "        self.hidden3 = nn.Linear(hidden_dim//2, hidden_dim)\n",
    "        self.leaky_relu3 = nn.LeakyReLU(negative_slope=0.01)\n",
    "\n",
    "        self.hidden4 = nn.Linear(hidden_dim, hidden_dim) \n",
    "        self.glu2 = nn.GLU() # half\n",
    "\n",
    "        self.hidden5 = nn.Linear(hidden_dim//2, input_dim) \n",
    "        self.leaky_relu5 = nn.LeakyReLU(negative_slope=0.01)\n",
    "\n",
    "        # 32 x 64 / 128 x 64\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.leaky_relu1(self.hidden1(x))\n",
    "        out = self.glu(self.hidden2(out))\n",
    "        out = self.leaky_relu3(self.hidden3(out))\n",
    "        out = self.glu2(self.hidden4(out))\n",
    "        out = self.leaky_relu5(self.hidden5(out))\n",
    "        return out\n",
    "\n",
    "class MovePredictionModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(MovePredictionModel, self).__init__()\n",
    "        self.input_layer = nn.Linear(input_dim, hidden_dim)\n",
    "        #self.leaky_relu = nn.LeakyReLU(negative_slope=0.3)\n",
    "\n",
    "        # Residual block\n",
    "        self.residual_block = ResidualBlock(input_dim, hidden_dim)\n",
    "\n",
    "        # self.hidden_skiplayer = nn.Linear(hidden_dim//2, input_dim)\n",
    "        self.hidden_skiplayer = nn.Linear(input_dim, hidden_dim)\n",
    "        self.leakyrelu_skiplayer = nn.LeakyReLU(negative_slope=0.01)\n",
    "\n",
    "        #self.hidden = nn.Linear(hidden_dim, output_dim)\n",
    "        #self.leakyrelu = nn.LeakyReLU(negative_slope=0.02)\n",
    "        self.output_layer = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        #processed_input = self.leaky_relu(self.input_layer(x))\n",
    "        processed_input = self.input_layer(x)\n",
    "        residual_out = self.residual_block(processed_input) # output tensor size: input_dim\n",
    "        \n",
    "        out = x + residual_out\n",
    "        out = self.hidden_skiplayer(out)\n",
    "        out = self.leakyrelu_skiplayer(out)\n",
    "        out = self.output_layer(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "INPUT_DIM = 9 # Linear vel + Linear acc + Angular vel + Angular acc + pos diff(vel*delta t) + rot diff(angvel * delta t) + bIsDrifting\n",
    "HIDDEN_DIM = 128\n",
    "OUTPUT_DIM = 3 # Pos diff x y  and rot diff z \n",
    "EPOCHS = 5000\n",
    "BATCH_SIZE = 64 # TODO\n",
    "LEARNING_RATE = 1e-4 #0.0005\n",
    "\n",
    "OUTPUT_FILENAME = 'model/test.pth'\n",
    "DATA_PATH = 'data'\n",
    "\n",
    "cuda_available = torch.cuda.is_available()\n",
    "print(cuda_available)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 6.7012e+01,  2.9694e+01,  0.0000e+00],\n",
      "        [ 7.6529e+01,  3.2894e+01, -5.2360e-02],\n",
      "        [ 8.6817e+01,  3.4000e+01, -5.2360e-02],\n",
      "        ...,\n",
      "        [-5.0843e+01, -2.8318e+01,  0.0000e+00],\n",
      "        [-2.8636e+01, -1.5950e+01,  0.0000e+00],\n",
      "        [-1.0118e+01, -5.6353e+00,  0.0000e+00]])\n",
      "tensor([ 1.7037e-01,  1.3411e+00, -3.8174e-04])\n",
      "torch.Size([64, 9])\n"
     ]
    }
   ],
   "source": [
    "# Read .csv files with pandas\n",
    "file_path = \"data/data0.csv\"\n",
    "data = pd.read_csv(file_path) # data frame \n",
    "\n",
    "# csv_file_paths = glob.glob(f'{DATA_PATH}/**/*.csv', recursive=True)\n",
    "# for path in csv_file_paths:\n",
    "#     print(path)\n",
    "\n",
    "# Convert to tensor \n",
    "x_features_csv = [i for i in range(9)] # 0 - 8 idx\n",
    "y_features_csv = [i for i in range(9, 12)] # 9 - 11 idx \n",
    "\n",
    "input_features = data.values[:,x_features_csv] # 0 - 8\n",
    "output_features = data.values[:, y_features_csv]\n",
    "\n",
    "# Min max scaling\n",
    "x_min, x_max = input_features.min(axis=0), input_features.max(axis=0)\n",
    "y_min, y_max = output_features.min(axis=0), output_features.max(axis=0)\n",
    "\n",
    "input_features_scaled = (input_features - x_min) / (x_max - x_min)\n",
    "#output_features_scaled = (output_features - y_min) / (y_max - y_min)\n",
    "\n",
    "X = torch.tensor(input_features_scaled, dtype=torch.float32)\n",
    "y = torch.tensor(output_features, dtype=torch.float32)\n",
    "\n",
    "print(y)\n",
    "print(torch.mean(y, dim=0))\n",
    "#print(X.shape, y.shape)\n",
    "\n",
    "# Dataset split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "val_dataset = TensorDataset(X_val, y_val)\n",
    " \n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "# print(f'Training samples: {len(train_loader.dataset)}')\n",
    "# print(f'Validation samples: {len(val_loader.dataset)}')\n",
    "\n",
    "batch = next(iter(train_loader))  # 첫 번째 배치 가져오기\n",
    "print(batch[0].shape) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Validation RMSE: 155.18922424316406\n",
      "New best model with RMSE: 155.18922424316406, saving model...\n",
      "Epoch 21, Validation RMSE: 100.74456024169922\n",
      "New best model with RMSE: 100.74456024169922, saving model...\n",
      "Epoch 41, Validation RMSE: 25.356351852416992\n",
      "New best model with RMSE: 25.356351852416992, saving model...\n",
      "Epoch 61, Validation RMSE: 14.6386079788208\n",
      "New best model with RMSE: 14.6386079788208, saving model...\n",
      "Epoch 81, Validation RMSE: 14.70494270324707\n",
      "Validation RMSE did not improve. Patience counter: 1/20\n",
      "Epoch 101, Validation RMSE: 12.266731262207031\n",
      "New best model with RMSE: 12.266731262207031, saving model...\n",
      "Epoch 121, Validation RMSE: 10.905355453491211\n",
      "New best model with RMSE: 10.905355453491211, saving model...\n",
      "Epoch 141, Validation RMSE: 9.770502090454102\n",
      "New best model with RMSE: 9.770502090454102, saving model...\n",
      "Epoch 161, Validation RMSE: 9.933758735656738\n",
      "Validation RMSE did not improve. Patience counter: 1/20\n",
      "Epoch 181, Validation RMSE: 10.743967056274414\n",
      "Validation RMSE did not improve. Patience counter: 2/20\n",
      "Epoch 201, Validation RMSE: 11.329641342163086\n",
      "Validation RMSE did not improve. Patience counter: 3/20\n",
      "Epoch 221, Validation RMSE: 11.445713996887207\n",
      "Validation RMSE did not improve. Patience counter: 4/20\n",
      "Epoch 241, Validation RMSE: 11.202091217041016\n",
      "Validation RMSE did not improve. Patience counter: 5/20\n",
      "Epoch 261, Validation RMSE: 9.855628967285156\n",
      "Validation RMSE did not improve. Patience counter: 6/20\n",
      "Epoch 281, Validation RMSE: 10.299657821655273\n",
      "Validation RMSE did not improve. Patience counter: 7/20\n",
      "Epoch 301, Validation RMSE: 8.584561347961426\n",
      "New best model with RMSE: 8.584561347961426, saving model...\n",
      "Epoch 321, Validation RMSE: 8.709373474121094\n",
      "Validation RMSE did not improve. Patience counter: 1/20\n",
      "Epoch 341, Validation RMSE: 8.170744895935059\n",
      "New best model with RMSE: 8.170744895935059, saving model...\n",
      "Epoch 361, Validation RMSE: 7.956667423248291\n",
      "New best model with RMSE: 7.956667423248291, saving model...\n",
      "Epoch 381, Validation RMSE: 7.934064865112305\n",
      "New best model with RMSE: 7.934064865112305, saving model...\n",
      "Epoch 401, Validation RMSE: 7.931913375854492\n",
      "New best model with RMSE: 7.931913375854492, saving model...\n",
      "Epoch 421, Validation RMSE: 8.165885925292969\n",
      "Validation RMSE did not improve. Patience counter: 1/20\n",
      "Epoch 441, Validation RMSE: 8.09816837310791\n",
      "Validation RMSE did not improve. Patience counter: 2/20\n",
      "Epoch 461, Validation RMSE: 8.520195007324219\n",
      "Validation RMSE did not improve. Patience counter: 3/20\n",
      "Epoch 481, Validation RMSE: 8.60478401184082\n",
      "Validation RMSE did not improve. Patience counter: 4/20\n",
      "Epoch 501, Validation RMSE: 9.118010520935059\n",
      "Validation RMSE did not improve. Patience counter: 5/20\n",
      "Epoch 521, Validation RMSE: 8.824464797973633\n",
      "Validation RMSE did not improve. Patience counter: 6/20\n",
      "Epoch 541, Validation RMSE: 8.487187385559082\n",
      "Validation RMSE did not improve. Patience counter: 7/20\n",
      "Epoch 561, Validation RMSE: 10.067654609680176\n",
      "Validation RMSE did not improve. Patience counter: 8/20\n",
      "Epoch 581, Validation RMSE: 10.729347229003906\n",
      "Validation RMSE did not improve. Patience counter: 9/20\n",
      "Epoch 601, Validation RMSE: 10.311594009399414\n",
      "Validation RMSE did not improve. Patience counter: 10/20\n",
      "Epoch 621, Validation RMSE: 9.023059844970703\n",
      "Validation RMSE did not improve. Patience counter: 11/20\n",
      "Epoch 641, Validation RMSE: 9.405094146728516\n",
      "Validation RMSE did not improve. Patience counter: 12/20\n",
      "Epoch 661, Validation RMSE: 10.21573257446289\n",
      "Validation RMSE did not improve. Patience counter: 13/20\n",
      "Epoch 681, Validation RMSE: 9.800725936889648\n",
      "Validation RMSE did not improve. Patience counter: 14/20\n",
      "Epoch 701, Validation RMSE: 9.57305908203125\n",
      "Validation RMSE did not improve. Patience counter: 15/20\n",
      "Epoch 721, Validation RMSE: 9.215548515319824\n",
      "Validation RMSE did not improve. Patience counter: 16/20\n",
      "Epoch 741, Validation RMSE: 9.678075790405273\n",
      "Validation RMSE did not improve. Patience counter: 17/20\n",
      "Epoch 761, Validation RMSE: 8.826905250549316\n",
      "Validation RMSE did not improve. Patience counter: 18/20\n",
      "Epoch 781, Validation RMSE: 9.048840522766113\n",
      "Validation RMSE did not improve. Patience counter: 19/20\n",
      "Epoch 801, Validation RMSE: 9.128573417663574\n",
      "Validation RMSE did not improve. Patience counter: 20/20\n",
      "Early stopping triggered. End loop\n"
     ]
    }
   ],
   "source": [
    "# Set model\n",
    "model = MovePredictionModel(INPUT_DIM, HIDDEN_DIM, OUTPUT_DIM)\n",
    "#model = ResidualBlock(INPUT_DIM, HIDDEN_DIM)\n",
    "if cuda_available:\n",
    "    model.cuda()\n",
    "\n",
    "epochs = EPOCHS\n",
    "best_val_rmse = float('inf')\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = LEARNING_RATE)\n",
    "\n",
    "loss_weights = torch.tensor([1,1,1e+2]) # Output features average >> [ 1.7037e-01,  1.3411e+00, -3.8174e-04] therefore I multiplied 1e+2 to the 3rd feature\n",
    "if cuda_available:\n",
    "    loss_weights = loss_weights.cuda()\n",
    "\n",
    "# Early stopping \n",
    "patience = 20\n",
    "es_counter = 0\n",
    "early_stop = False\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # Tranining \n",
    "    model.train()\n",
    "    #for X_batch, y_batch in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs} Training\"):\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        if cuda_available:\n",
    "            X_batch, y_batch = X_batch.cuda(), y_batch.cuda()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        y_pred = model(X_batch)\n",
    "\n",
    "        loss = criterion(y_pred * loss_weights, y_batch * loss_weights)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    if epoch % 20 == 0 or epoch == epochs-1:\n",
    "\n",
    "        model.eval()\n",
    "\n",
    "        val_rmse = []\n",
    "        y_preds = []\n",
    "        y_actuals = []\n",
    "        with torch.no_grad():\n",
    "            #for X_batch, y_batch in tqdm(val_loader, desc=f\"Epoch {epoch+1}/{epochs} Validation\"):\n",
    "            for X_batch, y_batch in val_loader:\n",
    "\n",
    "                ## if you have GPU\n",
    "                if cuda_available:\n",
    "                    X_batch, y_batch = X_batch.cuda(), y_batch.cuda()\n",
    "\n",
    "                # inference the model\n",
    "                y_pred = model(X_batch)\n",
    "\n",
    "                # calculate RMSE\n",
    "                rmse = torch.sqrt(criterion(y_pred, y_batch)).cpu().numpy()\n",
    "                val_rmse.append(rmse)\n",
    "\n",
    "                # for the first batch\n",
    "                if len(y_preds) == 0:  \n",
    "                    y_preds = y_pred.cpu().numpy()\n",
    "                    y_actuals = y_batch.cpu().numpy()\n",
    "                # for the rest of the batches\n",
    "                else:  \n",
    "                    y_preds = np.vstack((y_preds, y_pred.cpu().numpy()))\n",
    "                    y_actuals = np.vstack((y_actuals, y_batch.cpu().numpy()))\n",
    "        epoch_val_rmse = np.mean(val_rmse)\n",
    "        print(f\"Epoch {epoch+1}, Validation RMSE: {epoch_val_rmse}\")\n",
    "\n",
    "        if epoch_val_rmse < best_val_rmse:\n",
    "            best_val_rmse = epoch_val_rmse\n",
    "            print(f\"New best model with RMSE: {best_val_rmse}, saving model...\")\n",
    "            torch.save(model.state_dict(), OUTPUT_FILENAME)\n",
    "            es_counter = 0\n",
    "        else:\n",
    "            es_counter += 1\n",
    "            print(f\"Validation RMSE did not improve. Patience counter: {es_counter}/{patience}\")\n",
    "            if es_counter >= patience:\n",
    "                print(\"Early stopping triggered. End loop\")\n",
    "                early_stop = True\n",
    "                break\n",
    "    if early_stop:\n",
    "        model.load_state_dict(torch.load(output_features-OUTPUT_FILENAME))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\01076\\AppData\\Local\\Temp\\ipykernel_62660\\823936747.py:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(OUTPUT_FILENAME))  # pth 파일 로드\n"
     ]
    }
   ],
   "source": [
    "ONNX_PATH = \"model/KartPredictionModel.onnx\"\n",
    "\n",
    "# 모델 로드\n",
    "model = MovePredictionModel(INPUT_DIM, HIDDEN_DIM, OUTPUT_DIM)\n",
    "model.load_state_dict(torch.load(OUTPUT_FILENAME))  # pth 파일 로드\n",
    "model.eval()  # 평가 모드로 전환\n",
    "\n",
    "# 더미 입력 데이터 생성\n",
    "dummy_input = torch.randn(1, INPUT_DIM)  # 배치 크기=1, 입력 차원=9\n",
    "\n",
    "# ONNX 변환\n",
    "torch.onnx.export(\n",
    "    model, \n",
    "    dummy_input, \n",
    "    ONNX_PATH, \n",
    "    verbose=True, \n",
    "    input_names=['input'], \n",
    "    output_names=['output'], \n",
    "    dynamic_axes={'input': {0: 'batch_size'}, 'output': {0: 'batch_size'}}\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lstm_test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
